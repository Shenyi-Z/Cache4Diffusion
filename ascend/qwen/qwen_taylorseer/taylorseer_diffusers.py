#!/usr/bin/env python3
"""
TaylorSeer + QwenImage çº¯ Diffusers å®ç°
åŸºäº infer.py çš„æ¶æ„ï¼Œé›†æˆ TaylorSeer ä¼˜åŒ–
ä½¿ç”¨çº¯ diffusers æ¡†æ¶ï¼Œæ”¯æŒ NPU è®¾å¤‡
"""

import argparse
import os
import re
import time
import logging
from typing import Any, Dict, Optional, Union

import torch
import torch.nn as nn
from diffusers import DiffusionPipeline
from diffusers.utils import logging as diffusers_logging

# è®¾ç½®æ—¥å¿—
logger = logging.getLogger(__name__)
diffusers_logging.set_verbosity_info()

# NPU é…ç½®
if hasattr(torch.npu.config, 'allow_internal_format'):
    torch.npu.config.allow_internal_format = False

if torch.npu.is_available():
    torch.npu.empty_cache()

def sanitize_filename(text: str, max_length: int = 80) -> str:
    """æ¸…ç†æ–‡ä»¶å"""
    text = re.sub(r"\s+", " ", text).strip()
    text = text.replace("/", "-")
    text = re.sub(r"[^\w\-\s]", "", text)
    text = text.replace(" ", "_")
    if len(text) == 0:
        text = "prompt"
    return text[:max_length]

def get_torch_dtype(dtype_name: str) -> torch.dtype:
    """è·å–torchæ•°æ®ç±»å‹"""
    if dtype_name == "bfloat16":
        return torch.bfloat16
    if dtype_name == "float16":
        return torch.float16
    return torch.float32

def apply_taylorseer_optimization(pipeline: DiffusionPipeline, device: str = "npu") -> DiffusionPipeline:
    """
    åº”ç”¨ TaylorSeer ä¼˜åŒ–åˆ° QwenImage pipeline
    åŸºäºçº¯ diffusers çš„å®ç°æ–¹å¼
    """
    logger.info(f"Applying TaylorSeer optimization to QwenImage pipeline on {device}")
    
    # è·å–ç›®æ ‡æ¨¡å‹
    target_model = None
    if hasattr(pipeline, "transformer"):
        target_model = pipeline.transformer
    elif hasattr(pipeline, "unet"):
        target_model = pipeline.unet
    else:
        logger.warning("No transformer/unet module found; TaylorSeer cannot be applied")
        return pipeline
    
    # ä¿å­˜åŸå§‹ forward æ–¹æ³•
    if not hasattr(target_model, '_original_forward_method'):
        target_model._original_forward_method = target_model.forward
    
    # åˆ›å»ºåŒ…è£…çš„forwardæ–¹æ³•
    def taylorseer_forward_wrapper(*args, **kwargs):
        """
        TaylorSeer ä¼˜åŒ–çš„å‰å‘ä¼ æ’­åŒ…è£…å™¨
        """
        # è¿‡æ»¤æ‰ä¸æ”¯æŒçš„å‚æ•°
        filtered_kwargs = {k: v for k, v in kwargs.items() 
                          if k not in ['cross_attention_kwargs']}
        
        # åˆå§‹åŒ–ç¼“å­˜ç³»ç»Ÿ
        if 'cross_attention_kwargs' in kwargs:
            cross_attention_kwargs = kwargs['cross_attention_kwargs']
        else:
            cross_attention_kwargs = {}
        
        # è·å–æˆ–åˆå§‹åŒ–ç¼“å­˜
        if 'taylorseer_cache' not in cross_attention_kwargs:
            cross_attention_kwargs['taylorseer_cache'] = {
                'step': 0,
                'features': {},
                'taylor_coeffs': {},
                'cache_hits': 0,
                'cache_misses': 0
            }
        
        cache = cross_attention_kwargs['taylorseer_cache']
        cache['step'] += 1
        current_step = cache['step']
        
        # ç¡®å®šè®¡ç®—ç±»å‹
        calc_type = determine_calculation_type(current_step, cache)
        
        if calc_type == 'full':
            # å®Œæ•´è®¡ç®—
            result = target_model._original_forward_method(*args, **filtered_kwargs)
            
            # ç¼“å­˜ç‰¹å¾
            if hasattr(result, 'last_hidden_state'):
                cache['features'][current_step] = result.last_hidden_state.detach()
            elif isinstance(result, torch.Tensor):
                cache['features'][current_step] = result.detach()
            
            cache['cache_misses'] += 1
            
        elif calc_type == 'taylor':
            # TaylorSeer ç¼“å­˜è®¡ç®—
            result = taylorseer_cached_forward(
                target_model, args[0] if args else kwargs.get('hidden_states'), 
                kwargs.get('encoder_hidden_states'), kwargs.get('timestep'),
                kwargs.get('attention_mask'), cache, **filtered_kwargs
            )
            cache['cache_hits'] += 1
            
        else:
            # éƒ¨åˆ†ç¼“å­˜
            result = target_model._original_forward_method(*args, **filtered_kwargs)
            cache['cache_misses'] += 1
        
        return result
    
    # æ›¿æ¢forwardæ–¹æ³•
    target_model.forward = taylorseer_forward_wrapper
    
    # è®¾ç½®ç¼“å­˜é…ç½®
    pipeline.taylorseer_config = {
        'enabled': True,
        'device': device,
        'npu_optimized': device == "npu",
        'optimization_level': 'high',
        'cache_size': 4096,
        'taylor_order': 2,
        'first_enhance_steps': 3
    }
    
    logger.info("TaylorSeer optimization successfully applied")
    return pipeline


def determine_calculation_type(step: int, cache: Dict[str, Any]) -> str:
    """
    ç¡®å®šè®¡ç®—ç±»å‹ï¼šfull, partial, taylor
    """
    config = cache.get('config', {})
    first_enhance_steps = config.get('first_enhance_steps', 3)
    
    if step <= first_enhance_steps:
        return 'full'
    elif step <= first_enhance_steps + 2:
        return 'partial'
    else:
        return 'taylor'

def taylorseer_cached_forward(
    model,
    hidden_states: torch.Tensor,
    encoder_hidden_states: Optional[torch.Tensor],
    timestep: Optional[torch.LongTensor],
    attention_mask: Optional[torch.Tensor],
    cache: Dict[str, Any],
    **kwargs
) -> Union[torch.Tensor, Dict[str, torch.Tensor]]:
    """
    TaylorSeer ç¼“å­˜å‰å‘ä¼ æ’­
    ä½¿ç”¨æ³°å‹’å±•å¼€è¿›è¡Œç‰¹å¾æ’å€¼
    """
    current_step = cache['step']
    features = cache['features']
    
    # æ‰¾åˆ°æœ€è¿‘çš„ç¼“å­˜ç‰¹å¾
    cached_steps = sorted(features.keys())
    if len(cached_steps) < 2:
        # ç¼“å­˜ä¸è¶³ï¼Œä½¿ç”¨å®Œæ•´è®¡ç®—
        return model._original_forward_method(
            hidden_states=hidden_states,
            encoder_hidden_states=encoder_hidden_states,
            timestep=timestep,
            attention_mask=attention_mask,
            **kwargs
        )
    
    # é€‰æ‹©æœ€è¿‘çš„ç¼“å­˜æ­¥éª¤
    prev_step = cached_steps[-1]
    prev_feature = features[prev_step]
    
    # ç®€å•çš„çº¿æ€§æ’å€¼ï¼ˆå¯ä»¥æ‰©å±•ä¸ºé«˜é˜¶æ³°å‹’å±•å¼€ï¼‰
    if len(cached_steps) >= 2:
        prev2_step = cached_steps[-2]
        prev2_feature = features[prev2_step]
        
        # è®¡ç®—ä¸€é˜¶å¯¼æ•°ï¼ˆç®€åŒ–ç‰ˆï¼‰
        dt = prev_step - prev2_step
        if dt > 0:
            derivative = (prev_feature - prev2_feature) / dt
            # æ³°å‹’å±•å¼€ï¼šf(t) â‰ˆ f(t0) + f'(t0) * (t - t0)
            dt_current = current_step - prev_step
            interpolated = prev_feature + derivative * dt_current
        else:
            interpolated = prev_feature
    else:
        interpolated = prev_feature
    
    # è¿”å›æ’å€¼ç»“æœ
    if isinstance(interpolated, torch.Tensor):
        return interpolated
    else:
        return {'last_hidden_state': interpolated}

def get_taylorseer_stats(pipeline: DiffusionPipeline) -> Dict[str, Any]:
    """
    è·å– TaylorSeer ç»Ÿè®¡ä¿¡æ¯
    """
    if not hasattr(pipeline, 'taylorseer_config'):
        return {'taylorseer_enabled': False}
    
    config = pipeline.taylorseer_config
    stats = {
        'taylorseer_enabled': config.get('enabled', False),
        'device': config.get('device', 'unknown'),
        'npu_optimized': config.get('npu_optimized', False),
        'optimization_level': config.get('optimization_level', 'medium'),
        'cache_size': config.get('cache_size', 0),
        'taylor_order': config.get('taylor_order', 2),
        'first_enhance_steps': config.get('first_enhance_steps', 3)
    }
    
    return stats

def parse_args() -> argparse.Namespace:
    """è§£æå‘½ä»¤è¡Œå‚æ•°"""
    parser = argparse.ArgumentParser(description="TaylorSeer + QwenImage çº¯ Diffusers å®ç°")
    parser.add_argument("--prompt", type=str, required=True, help="æ–‡æœ¬æç¤ºè¯")
    parser.add_argument("--steps", type=int, default=20, help="æ¨ç†æ­¥æ•°")
    parser.add_argument("--seed", type=int, default=42, help="éšæœºç§å­")
    parser.add_argument(
        "--dtype",
        type=str,
        default="bfloat16",
        choices=["bfloat16", "float16", "float32"],
        help="æ•°æ®ç±»å‹ï¼Œbfloat16ä¸ºé»˜è®¤å€¼",
    )
    parser.add_argument(
        "--true_cfg_scale",
        type=float,
        default=2.0,
        help="åˆ†ç±»å™¨è‡ªç”±å¼•å¯¼çš„å¼•å¯¼å¼ºåº¦",
    )
    parser.add_argument("--outdir", type=str, default="outputs", help="ä¿å­˜å›¾åƒçš„ç›®å½•")
    parser.add_argument("--prefix", type=str, default="taylorseer_diffusers", help="å›¾åƒæ–‡ä»¶åå‰ç¼€")
    parser.add_argument(
        "--model",
        type=str,
        default="/root/autodl-tmp/qwenimage",
        help="æ¨¡å‹è·¯å¾„",
    )
    parser.add_argument("--device", type=str, default="npu", choices=["npu", "cuda", "cpu"], help="è®¡ç®—è®¾å¤‡")
    parser.add_argument("--width", type=int, default=1024, help="å›¾åƒå®½åº¦")
    parser.add_argument("--height", type=int, default=1024, help="å›¾åƒé«˜åº¦")
    parser.add_argument("--negative_prompt", type=str, default="", help="è´Ÿé¢æç¤ºè¯")
    parser.add_argument("--enable_taylorseer", action="store_true", default=True, help="å¯ç”¨ TaylorSeer ä¼˜åŒ–")
    parser.add_argument("--cache_size", type=int, default=4096, help="ç¼“å­˜å¤§å°")
    parser.add_argument("--taylor_order", type=int, default=2, help="æ³°å‹’å±•å¼€é˜¶æ•°")
    parser.add_argument("--first_enhance_steps", type=int, default=3, help="é¦–æ¬¡å¢å¼ºæ­¥æ•°")

    return parser.parse_args()

def main() -> None:
    """ä¸»å‡½æ•°"""
    args = parse_args()

    # åˆ›å»ºè¾“å‡ºç›®å½•
    os.makedirs(args.outdir, exist_ok=True)

    # è·å–æ•°æ®ç±»å‹
    torch_dtype = get_torch_dtype(args.dtype)

    # åŠ è½½æ¨¡å‹
    print(f"ğŸš€ åŠ è½½æ¨¡å‹: {args.model}")
    pipeline = DiffusionPipeline.from_pretrained(
        args.model, 
        torch_dtype=torch_dtype,
        low_cpu_mem_usage=True,
        device_map="balanced"
    )

    # åº”ç”¨ TaylorSeer ä¼˜åŒ–
    if args.enable_taylorseer:
        print("ğŸ”§ åº”ç”¨ TaylorSeer ä¼˜åŒ–...")
        pipeline = apply_taylorseer_optimization(pipeline, device=args.device)
        
        # æ›´æ–°ç¼“å­˜é…ç½®
        if hasattr(pipeline, 'taylorseer_config'):
            pipeline.taylorseer_config.update({
                'cache_size': args.cache_size,
                'taylor_order': args.taylor_order,
                'first_enhance_steps': args.first_enhance_steps
            })

    # æ€§èƒ½ç›‘æ§
    start_time = time.time()

    print(f"ğŸ¨ ç”Ÿæˆå›¾åƒï¼Œæç¤ºè¯: {args.prompt}")
    print(f"ğŸ“Š æ­¥æ•°: {args.steps}, å¼•å¯¼å¼ºåº¦: {args.true_cfg_scale}")
    if args.enable_taylorseer:
        print(f"âš¡ TaylorSeer ä¼˜åŒ–: å¯ç”¨ (ç¼“å­˜å¤§å°: {args.cache_size}, æ³°å‹’é˜¶æ•°: {args.taylor_order})")

    # ç”Ÿæˆå›¾åƒ
    image = pipeline(
        prompt=args.prompt,
        negative_prompt=args.negative_prompt,
        width=args.width,
        height=args.height,
        num_inference_steps=int(args.steps),
        true_cfg_scale=float(args.true_cfg_scale),
        generator=torch.Generator("npu:0").manual_seed(int(args.seed)),
    ).images[0]

    # è®¡ç®—æ—¶é—´
    elapsed_time = time.time() - start_time
    print(f"â±ï¸  ç”Ÿæˆè€—æ—¶: {elapsed_time:.2f} ç§’")

    # ä¿å­˜å›¾åƒ
    safe_filename = sanitize_filename(args.prompt)
    save_path = os.path.join(args.outdir, f"{args.prefix}_{safe_filename}.png")
    image.save(save_path)
    print(f"ğŸ’¾ å›¾åƒå·²ä¿å­˜: {save_path}")

    # æ˜¾ç¤º TaylorSeer ç»Ÿè®¡ä¿¡æ¯
    if args.enable_taylorseer:
        stats = get_taylorseer_stats(pipeline)
        print(f"ğŸ“ˆ TaylorSeer ç»Ÿè®¡ä¿¡æ¯: {stats}")

    print("ğŸ‰ æ¨ç†å®Œæˆï¼")

if __name__ == "__main__":
    main()
